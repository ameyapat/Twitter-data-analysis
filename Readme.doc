{\rtf1\ansi\ansicpg1252\deff0
{\fonttbl
{\f0\fnil\fcharset0\fprq0\fttruetype FreeSans;}
{\f1\fnil\fcharset0\fprq0\fttruetype Times New Roman;}
{\f2\fnil\fcharset0\fprq0\fttruetype Liberation Sans;}
{\f3\fnil\fcharset0\fprq0\fttruetype Dingbats;}
{\f4\fnil\fcharset0\fprq0\fttruetype Symbol;}
{\f5\fnil\fcharset0\fprq0\fttruetype Courier New;}}
{\colortbl
\red0\green0\blue0;
\red255\green255\blue255;
\red255\green255\blue255;}
{\stylesheet
{\s1\fi-427\li720\sbasedon29\snext29 Contents 1;}
{\s2\fi-427\li1440\sbasedon29\snext29 Contents 2;}
{\s3\fi-427\li2160\sbasedon29\snext29 Contents 3;}
{\s8\fi-427\li720\sbasedon29 Lower Roman List;}
{\s5\tx431\sbasedon25\snext29 Numbered Heading 1;}
{\s6\tx431\sbasedon26\snext29 Numbered Heading 2;}
{\s7\fi-427\li720 Square List;}
{\s12\sbasedon29 Endnote Text;}
{\s22\fi-427\li720 Bullet List;}
{\s4\fi-427\li2880\sbasedon29\snext29 Contents 4;}
{\s10\fi-427\li720 Diamond List;}
{\s11\fi-427\li720 Numbered List;}
{\*\cs13\fs20\super Endnote Reference;}
{\s14\fi-427\li720 Triangle List;}
{\s15\tx431\sbasedon27\snext29 Numbered Heading 3;}
{\s16\fi-427\li720 Dashed List;}
{\s17\fi-427\li720\sbasedon11 Upper Roman List;}
{\s18\sb440\sa60\f2\fs24\b\sbasedon29\snext29 Heading 4;}
{\s19\fi-427\li720 Heart List;}
{\s35\fi-427\li720 Box List;}
{\s21\fi-427\li720\sbasedon11 Upper Case List;}
{\s9\fi-288\li288\fs20\sbasedon29 Footnote;}
{\s23\fi-427\li720 Hand List;}
{\s24\fs20\sbasedon29 Footnote Text;}
{\s25\sb440\sa60\f2\fs34\b\sbasedon29\snext29 Heading 1;}
{\s26\sb440\sa60\f2\fs28\b\sbasedon29\snext29 Heading 2;}
{\s20\qc\sb240\sa117\f2\fs32\b\sbasedon29\snext29 Contents Header;}
{\s28\fi-427\li720 Tick List;}
{\s27\sb440\sa60\f2\fs24\b\sbasedon29\snext29 Heading 3;}
{\s30\fi-427\li720\sbasedon11 Lower Case List;}
{\s31\li1440\ri1440\sa117\sbasedon29 Block Text;}
{\s37\f5\sbasedon29 Plain Text;}
{\s33\tx1584\sbasedon5\snext29 Section Heading;}
{\s34\fi-427\li720 Implies List;}
{\s29\f1\fs24 Normal;}
{\s36\fi-427\li720 Star List;}
{\*\cs32\fs20\super Footnote Reference;}
{\s38\tx1584\sbasedon5\snext29 Chapter Heading;}
{\s39\fi-288\li288\sbasedon29 Endnote;}}
{\*\listtable
{\list\listtemplateid1072\listsimple{\listlevel\levelnfc2\levelstartat1\levelspace0\levelfollow0\fi-427\li720{\leveltext\'02\'00.;}{\levelnumbers\'01;}}\listid1069}
{\list\listtemplateid1073\listsimple{\listlevel\levelnfc2\levelstartat1\levelspace0\levelfollow0\fi-427\li720{\leveltext\'02\'00.;}{\levelnumbers\'01;}}\listid1075}
{\list\listtemplateid1074\listsimple{\listlevel\levelnfc2\levelstartat1\levelspace0\levelfollow0\fi-427\li720{\leveltext\'02\'00.;}{\levelnumbers\'01;}}\listid1080}
{\list\listtemplateid1075\listsimple{\listlevel\levelnfc2\levelstartat1\levelspace0\levelfollow0\fi-427\li720{\leveltext\'02\'00.;}{\levelnumbers\'01;}}\listid1000}
{\list\listtemplateid1076\listsimple{\listlevel\levelnfc2\levelstartat1\levelspace0\levelfollow0\fi-427\li720{\leveltext\'02\'00.;}{\levelnumbers\'01;}}\listid1061}
{\list\listtemplateid1077\listsimple{\listlevel\levelnfc2\levelstartat1\levelspace0\levelfollow0\fi-427\li720{\leveltext\'02\'00.;}{\levelnumbers\'01;}}\listid1052}}
{\*\listoverridetable
{\listoverride\listoverridecount0\listid1069\levelnfc2\levelstartat1\levelspace0\levelfollow0\fi-427\li720{\leveltext\'02\'00.;}{\levelnumbers\'01;}\ls1}
{\listoverride\listoverridecount0\listid1075\levelnfc2\levelstartat1\levelspace0\levelfollow0\fi-427\li720{\leveltext\'02\'00.;}{\levelnumbers\'01;}\ls2}
{\listoverride\listoverridecount0\listid1080\levelnfc2\levelstartat1\levelspace0\levelfollow0\fi-427\li720{\leveltext\'02\'00.;}{\levelnumbers\'01;}\ls3}
{\listoverride\listoverridecount0\listid1000\levelnfc2\levelstartat1\levelspace0\levelfollow0\fi-427\li720{\leveltext\'02\'00.;}{\levelnumbers\'01;}\ls4}
{\listoverride\listoverridecount0\listid1061\levelnfc2\levelstartat1\levelspace0\levelfollow0\fi-427\li720{\leveltext\'02\'00.;}{\levelnumbers\'01;}\ls5}
{\listoverride\listoverridecount0\listid1052\levelnfc2\levelstartat1\levelspace0\levelfollow0\fi-427\li720{\leveltext\'02\'00.;}{\levelnumbers\'01;}\ls6}}

\kerning0\cf0\ftnbj\fet2\ftnstart1\ftnnar\aftnnar\ftnstart1\aftnstart1\aenddoc\revprop3{\*\rdf}{\info\uc1}\deftab720\viewkind1\paperw12240\paperh15840\margl1440\margr1440\widowctrl
\sectd\sbknone\colsx360\pgncont\ltrsect
\pard\plain\ltrpar\qc\s29\sl240\slmult1\itap0{\s29\f0\fs28\lang1033{\*\listtag0}\abinodiroverride\ltrch README}{\s29\f0\fs28\lang1033{\*\listtag0}\par}
\pard\plain\ltrpar\ql\s29\sl240\slmult1\itap0{\s29\f0\fs24\lang1033{\*\listtag0}\abinodiroverride\ltrch ---------------------------------------------------------------------------------------------------------------------}{\s29\f0\fs24\lang1033{\*\listtag0}\par}
\pard\plain\ltrpar\ql\s29\sl240\slmult1\itap0{\s29\f0\fs24\ul\lang1033{\*\listtag0}\abinodiroverride\ltrch The TweetCollector folder contains sample data}{\s29\f0\fs24\ul\lang1033{\*\listtag0}\par}
\pard\plain\ltrpar\ql\s29\sl240\slmult1\itap0{\s29\f0\fs24\lang1033{\*\listtag0}\abinodiroverride\ltrch This project was done in the following 5 phases, namely\~:}{\s29\f0\fs24\lang1033{\*\listtag0}\par}
\pard\plain\ltrpar\ql\s29\sl240\slmult1\itap0{\s29\f0\fs24\lang1033{\*\listtag0}\abinodiroverride\ltrch ) Tweet Collection using Twitter Stream API in Java.}{\s29\f0\fs24\lang1033{\*\listtag0}\par}
\pard\plain\ltrpar\ql\s29\sl240\slmult1\itap0{\s29\f0\fs24\lang1033{\*\listtag0}\abinodiroverride\ltrch ) Parsing Collected tweets into sub-text files using Python.}{\s29\f0\fs24\lang1033{\*\listtag0}\par}
\pard\plain\ltrpar\ql\s29\sl240\slmult1\itap0{\s29\f0\fs24\lang1033{\*\listtag0}\abinodiroverride\ltrch ) Map Reduce jobs on parsed files to get required output.}{\s29\f0\fs24\lang1033{\*\listtag0}\par}
\pard\plain\ltrpar\ql\fi-360\li360\s29\sl240\slmult1\itap0{\s29\f0\fs24\lang1033{\*\listtag0}\abinodiroverride\ltrch i. Word-count on #tags to find top trending/popular #tags from collected tweets.}{\s29\f0\fs24\lang1033{\*\listtag0}\par}
\pard\plain\ltrpar\ql\fi-360\li360\s29\sl240\slmult1\itap0{\s29\f0\fs24\lang1033{\*\listtag0}\abinodiroverride\ltrch ii. Word-count on @user-names to find top tweeters\~}{\s29\f0\fs24\lang1033{\*\listtag0}\par}
\pard\plain\ltrpar\ql\fi-360\li360\s29\sl240\slmult1\itap0{\s29\f0\fs24\lang1033{\*\listtag0}\abinodiroverride\ltrch iii. Pairs and Strips algorithm to find top Co-occurrence.}{\s29\f0\fs24\lang1033{\*\listtag0}\par}
\pard\plain\ltrpar\ql\s29\sl240\slmult1\itap0{\s29\f0\fs24\lang1033{\*\listtag0}\abinodiroverride\ltrch ) Map Reduce job to perform K-Means algorithm to cluster no. of followers of users into  3 clusters.}{\s29\f0\fs24\lang1033{\*\listtag0}\par}
\pard\plain\ltrpar\ql\s29\sl240\slmult1\itap0{\s29\f0\fs24\lang1033{\*\listtag0}\abinodiroverride\ltrch ) Map Reduce job to find single source shortest path between any node and source in given graph.}{\s29\f0\fs24\lang1033{\*\listtag0}\par}
\pard\plain\ltrpar\ql\s29\sl240\slmult1\itap0{\s29\f0\fs24\lang1033{\*\listtag0}\abinodiroverride\ltrch ---------------------------------------------------------------------------------------------------------------------}{\s29\f0\fs24\lang1033{\*\listtag0}\par}
\pard\plain\ltrpar\ql\s29\sl240\slmult1\itap0{\s29\f0\fs24\lang1033{\*\listtag0}\par}
\pard\plain\ltrpar\ql\s29\sl240\slmult1\itap0{\s29\f0\fs24\ul\lang1033{\*\listtag0}\abinodiroverride\ltrch . Tweet Collection using Twitter API}{\s29\f0\fs24\ul\lang1033{\*\listtag0}\par}
\pard\plain\ltrpar\ql\s29\sl240\slmult1\itap0{\s29\f0\fs24\ul\lang1033{\*\listtag0}\par}
{\listtext\pard\fi-427\li720 i.	}\pard\plain{\ltrpar\ql\fi-427\li720\s29{\*\abilist\abilistid1069\abilistparentid0\abilistlevel1\abistartat1{\abifieldfont NULL}{\abilistdecimal .}{\abilistdelim %L.}{\abiliststyle Lower Roman List}}{\*\pn\pnql\pnstart1\pnlvlbody\pnlcrm{\pntxtb }{\pntxta .}}\fn-427\li720\ls1\ilvl0\sl240\slmult1\itap0{\s29\f0\fs24\lang1033{\*\listtag0}\abinodiroverride\ltrch Import the TweetCollector folder in Eclipse.}{\s29\f0\fs24\ul\lang1033{\*\listtag0}\par}
}{\listtext\pard\fi-427\li720 ii.	}\pard\plain{\ltrpar\ql\fi-427\li720\s29{\*\abilist\abilistid1069\abilistparentid0\abilistlevel1\abistartat1{\abifieldfont NULL}{\abilistdecimal .}{\abilistdelim %L.}{\abiliststyle Lower Roman List}}{\*\pn\pnql\pnstart1\pnlvlbody\pnlcrm{\pntxtb }{\pntxta .}}\fn-427\li720\ls1\ilvl0\sl240\slmult1\itap0{\s29\f0\fs24\lang1033{\*\listtag0}\abinodiroverride\ltrch Enter your Twitter developer provided API keys in auth.ConfigBuilder.java file for authentication.}{\s29\f0\fs24\lang1033{\*\listtag0}\par}
}{\listtext\pard\fi-427\li720 iii.	}\pard\plain{\ltrpar\ql\fi-427\li720\s29{\*\abilist\abilistid1069\abilistparentid0\abilistlevel1\abistartat1{\abifieldfont NULL}{\abilistdecimal .}{\abilistdelim %L.}{\abiliststyle Lower Roman List}}{\*\pn\pnql\pnstart1\pnlvlbody\pnlcrm{\pntxtb }{\pntxta .}}\fn-427\li720\ls1\ilvl0\sl240\slmult1\itap0{\s29\f0\fs24\lang1033{\*\listtag0}\abinodiroverride\ltrch Run the program in Eclipse for desired amount of time.}{\s29\f0\fs24\lang1033{\*\listtag0}\par}
}{\listtext\pard\fi-427\li720 iv.	}\pard\plain{\ltrpar\ql\fi-427\li720\s29{\*\abilist\abilistid1069\abilistparentid0\abilistlevel1\abistartat1{\abifieldfont NULL}{\abilistdecimal .}{\abilistdelim %L.}{\abiliststyle Lower Roman List}}{\*\pn\pnql\pnstart1\pnlvlbody\pnlcrm{\pntxtb }{\pntxta .}}\fn-427\li720\ls1\ilvl0\sl240\slmult1\itap0{\s29\f0\fs24\lang1033{\*\listtag0}\abinodiroverride\ltrch Program will create a file in TweetCollector folder which contains the required details from collected tweets.}{\s29\f0\fs24\lang1033{\*\listtag0}\par}
}\pard\plain\ltrpar\ql\s29\sl240\slmult1\itap0{\s29\f0\fs24\lang1033{\*\listtag0}\par}
\pard\plain\ltrpar\ql\s29\sl240\slmult1\itap0{\s29\f0\fs24\ul\lang1033{\*\listtag0}\abinodiroverride\ltrch . Parsing Collected tweets into sub-text files using Python.}{\s29\f0\fs24\ul\lang1033{\*\listtag0}\par}
\pard\plain\ltrpar\ql\s29\sl240\slmult1\itap0{\s29\f0\fs24\ul\lang1033{\*\listtag0}\par}
{\listtext\pard\fi-427\li720 i.	}\pard\plain{\ltrpar\ql\fi-427\li720\s29{\*\abilist\abilistid1075\abilistparentid0\abilistlevel1\abistartat1{\abifieldfont NULL}{\abilistdecimal .}{\abilistdelim %L.}{\abiliststyle Lower Roman List}}{\*\pn\pnql\pnstart1\pnlvlbody\pnlcrm{\pntxtb }{\pntxta .}}\fn-427\li720\ls2\ilvl0\sl240\slmult1\itap0{\s29\f0\fs24\lang1033{\*\listtag0}\abinodiroverride\ltrch Open terminal and run python scripts in the TweetCollector folder.}{\s29\f0\fs24\ul\lang1033{\*\listtag0}\par}
}{\listtext\pard\fi-427\li720 ii.	}\pard\plain{\ltrpar\ql\fi-427\li720\s29{\*\abilist\abilistid1075\abilistparentid0\abilistlevel1\abistartat1{\abifieldfont NULL}{\abilistdecimal .}{\abilistdelim %L.}{\abiliststyle Lower Roman List}}{\*\pn\pnql\pnstart1\pnlvlbody\pnlcrm{\pntxtb }{\pntxta .}}\fn-427\li720\ls2\ilvl0\sl240\slmult1\itap0{\s29\f0\fs24\lang1033{\*\listtag0}\abinodiroverride\ltrch Cd into the TweetCollector folder.Type python <script-name>.py to run a python script.}{\s29\f0\fs24\lang1033{\*\listtag0}\par}
}{\listtext\pard\fi-427\li720 iii.	}\pard\plain{\ltrpar\ql\fi-427\li720\s29{\*\abilist\abilistid1075\abilistparentid0\abilistlevel1\abistartat1{\abifieldfont NULL}{\abilistdecimal .}{\abilistdelim %L.}{\abiliststyle Lower Roman List}}{\*\pn\pnql\pnstart1\pnlvlbody\pnlcrm{\pntxtb }{\pntxta .}}\fn-427\li720\ls2\ilvl0\sl240\slmult1\itap0{\s29\f0\fs24\lang1033{\*\listtag0}\abinodiroverride\ltrch Run hashtagspertweet.py, userparser.py, usergraphparser.py , parser.py according to above mentioned steps.}{\s29\f0\fs24\lang1033{\*\listtag0}\par}
}\pard\plain\ltrpar\ql\s29\sl240\slmult1\itap0{\s29\f0\fs24\lang1033{\*\listtag0}\par}
\pard\plain\ltrpar\ql\s29\sl240\slmult1\itap0{\s29\f0\fs24\ul\lang1033{\*\listtag0}\abinodiroverride\ltrch .i) and 3.ii) Map reduce job to run Word Count on Hash Tags and @usernames}{\s29\f0\fs24\ul\lang1033{\*\listtag0}\par}
\pard\plain\ltrpar\ql\s29\sl240\slmult1\itap0{\s29\f0\fs24\ul\lang1033{\*\listtag0}\par}
{\listtext\pard\fi-427\li720 i.	}\pard\plain{\ltrpar\ql\fi-427\li720\s29{\*\abilist\abilistid1080\abilistparentid0\abilistlevel1\abistartat1{\abifieldfont NULL}{\abilistdecimal .}{\abilistdelim %L.}{\abiliststyle Lower Roman List}}{\*\pn\pnql\pnstart1\pnlvlbody\pnlcrm{\pntxtb }{\pntxta .}}\fn-427\li720\ls3\ilvl0\sl240\slmult1\itap0{\s29\f0\fs24\lang1033{\*\listtag0}\abinodiroverride\ltrch Copy the wordcount-sample.jar file from Jars folder to home or any other location.}{\s29\f0\fs24\ul\lang1033{\*\listtag0}\par}
}{\listtext\pard\fi-427\li720 ii.	}\pard\plain{\ltrpar\ql\fi-427\li720\s29{\*\abilist\abilistid1080\abilistparentid0\abilistlevel1\abistartat1{\abifieldfont NULL}{\abilistdecimal .}{\abilistdelim %L.}{\abiliststyle Lower Roman List}}{\*\pn\pnql\pnstart1\pnlvlbody\pnlcrm{\pntxtb }{\pntxta .}}\fn-427\li720\ls3\ilvl0\sl240\slmult1\itap0{\s29\f0\fs24\lang1033{\*\listtag0}\abinodiroverride\ltrch Run Map reduce job using the provided jar by typing \uc1\u8220\'93}{\s29\f1\fs24\lang1033{\*\listtag0}hadoop jar wordcount-sample.jar sample.WordCount\uc1\u8221\'94 }{\s29\f0\fs24\lang1033{\*\listtag0}in the terminal after staring hadoop dfs and yarn.}{\s29\f0\fs24\lang1033{\*\listtag0}\par}
}{\listtext\pard\fi-427\li720 iii.	}\pard\plain{\ltrpar\ql\fi-427\li720\s29{\*\abilist\abilistid1080\abilistparentid0\abilistlevel1\abistartat1{\abifieldfont NULL}{\abilistdecimal .}{\abilistdelim %L.}{\abiliststyle Lower Roman List}}{\*\pn\pnql\pnstart1\pnlvlbody\pnlcrm{\pntxtb }{\pntxta .}}\fn-427\li720\ls3\ilvl0\sl240\slmult1\itap0{\s29\f0\fs24\lang1033{\*\listtag0}\abinodiroverride\ltrch After job completes type to copy output folder to Local FileSystem.}{\s29\f0\fs24\lang1033{\*\listtag0}\par}
}{\listtext\pard\fi-427\li720 iv.	}\pard\plain{\ltrpar\ql\fi-427\li720\s29{\*\abilist\abilistid1080\abilistparentid0\abilistlevel1\abistartat1{\abifieldfont NULL}{\abilistdecimal .}{\abilistdelim %L.}{\abiliststyle Lower Roman List}}{\*\pn\pnql\pnstart1\pnlvlbody\pnlcrm{\pntxtb }{\pntxta .}}\fn-427\li720\ls3\ilvl0\sl240\slmult1\itap0{\s29\f0\fs24\lang1033{\*\listtag0}\abinodiroverride\ltrch Cd into output folder and type to get the output no. of HashTags in csv format.}{\s29\f0\fs24\lang1033{\*\listtag0}\par}
}{\listtext\pard\fi-427\li720 v.	}\pard\plain{\ltrpar\ql\fi-427\li720\s29{\*\abilist\abilistid1080\abilistparentid0\abilistlevel1\abistartat1{\abifieldfont NULL}{\abilistdecimal .}{\abilistdelim %L.}{\abiliststyle Lower Roman List}}{\*\pn\pnql\pnstart1\pnlvlbody\pnlcrm{\pntxtb }{\pntxta .}}\fn-427\li720\ls3\ilvl0\sl240\slmult1\itap0{\s29\f0\fs24\lang1033{\*\listtag0}\abinodiroverride\ltrch Type \uc1\u8220\'93hdfs dfs -rm /input/*.txt\uc1\u8221\'94 to remove all files from the /input folder and upload the usernames.txt from TweetCollector folder to hdfs /input.}{\s29\f0\fs24\lang1033{\*\listtag0}\par}
}{\listtext\pard\fi-427\li720 vi.	}\pard\plain{\ltrpar\ql\fi-427\li720\s29{\*\abilist\abilistid1080\abilistparentid0\abilistlevel1\abistartat1{\abifieldfont NULL}{\abilistdecimal .}{\abilistdelim %L.}{\abiliststyle Lower Roman List}}{\*\pn\pnql\pnstart1\pnlvlbody\pnlcrm{\pntxtb }{\pntxta .}}\fn-427\li720\ls3\ilvl0\sl240\slmult1\itap0{\s29\f0\fs24\lang1033{\*\listtag0}\abinodiroverride\ltrch vi.Follow steps iii. to v. to get result for @usernames count.}{\s29\f0\fs24\lang1033{\*\listtag0}\par}
}\pard\plain\ltrpar\ql\s29\sl240\slmult1\itap0{\s29\f0\fs24\lang1033{\*\listtag0}\par}
\pard\plain\ltrpar\ql\s29\sl240\slmult1\itap0{\s29\f0\fs24\ul\lang1033{\*\listtag0}\abinodiroverride\ltrch . iii) Find Co-occuring HashTags using Pairs and Strips algorithm in Hadoop MapReduce}{\s29\f0\fs24\ul\lang1033{\*\listtag0}\par}
\pard\plain\ltrpar\ql\s29\sl240\slmult1\itap0{\s29\f0\fs24\ul\lang1033{\*\listtag0}\par}
{\listtext\pard\fi-427\li720 i.	}\pard\plain{\ltrpar\ql\fi-427\li720\s29{\*\abilist\abilistid1000\abilistparentid0\abilistlevel1\abistartat1{\abifieldfont NULL}{\abilistdecimal .}{\abilistdelim %L.}{\abiliststyle Lower Roman List}}{\*\pn\pnql\pnstart1\pnlvlbody\pnlcrm{\pntxtb }{\pntxta .}}\fn-427\li720\ls4\ilvl0\sl240\slmult1\itap0{\s29\f0\fs24\lang1033{\*\listtag0}\abinodiroverride\ltrch Type \uc1\u8220\'93hdfs dfs -rm /input/*.txt\uc1\u8221\'94 to remove all files from the /input folder and upload the hashtags_bytweet.txt from TweetCollector folder to hdfs /input.}{\s29\f0\fs24\ul\lang1033{\*\listtag0}\par}
}{\listtext\pard\fi-427\li720 ii.	}\pard\plain{\ltrpar\ql\fi-427\li720\s29{\*\abilist\abilistid1000\abilistparentid0\abilistlevel1\abistartat1{\abifieldfont NULL}{\abilistdecimal .}{\abilistdelim %L.}{\abiliststyle Lower Roman List}}{\*\pn\pnql\pnstart1\pnlvlbody\pnlcrm{\pntxtb }{\pntxta .}}\fn-427\li720\ls4\ilvl0\sl240\slmult1\itap0{\s29\f0\fs24\lang1033{\*\listtag0}\abinodiroverride\ltrch Run Map reduce job using the provided jar by typing \uc1\u8220\'93}{\s29\f1\fs24\lang1033{\*\listtag0}hadoop jar paircount-sample.jar sample.PairCount}{\s29\f0\fs24\lang1033{\*\listtag0}\uc1\u8221\'94 in the terminal after staring hadoop dfs and yarn.}{\s29\f0\fs24\lang1033{\*\listtag0}\par}
}{\listtext\pard\fi-427\li720 iii.	}\pard\plain{\ltrpar\ql\fi-427\li720\s29{\*\abilist\abilistid1000\abilistparentid0\abilistlevel1\abistartat1{\abifieldfont NULL}{\abilistdecimal .}{\abilistdelim %L.}{\abiliststyle Lower Roman List}}{\*\pn\pnql\pnstart1\pnlvlbody\pnlcrm{\pntxtb }{\pntxta .}}\fn-427\li720\ls4\ilvl0\sl240\slmult1\itap0{\s29\f0\fs24\lang1033{\*\listtag0}\abinodiroverride\ltrch After job completes type to copy output folder to Local FileSystem.}{\s29\f0\fs24\lang1033{\*\listtag0}\par}
}{\listtext\pard\fi-427\li720 iv.	}\pard\plain{\ltrpar\ql\fi-427\li720\s29{\*\abilist\abilistid1000\abilistparentid0\abilistlevel1\abistartat1{\abifieldfont NULL}{\abilistdecimal .}{\abilistdelim %L.}{\abiliststyle Lower Roman List}}{\*\pn\pnql\pnstart1\pnlvlbody\pnlcrm{\pntxtb }{\pntxta .}}\fn-427\li720\ls4\ilvl0\sl240\slmult1\itap0{\s29\f0\fs24\lang1033{\*\listtag0}\abinodiroverride\ltrch Cd into output folder and type  to get the output co-occurring hash tags in csv format.}{\s29\f0\fs24\lang1033{\*\listtag0}\par}
}{\listtext\pard\fi-427\li720 v.	}\pard\plain{\ltrpar\ql\fi-427\li720\s29{\*\abilist\abilistid1000\abilistparentid0\abilistlevel1\abistartat1{\abifieldfont NULL}{\abilistdecimal .}{\abilistdelim %L.}{\abiliststyle Lower Roman List}}{\*\pn\pnql\pnstart1\pnlvlbody\pnlcrm{\pntxtb }{\pntxta .}}\fn-427\li720\ls4\ilvl0\sl240\slmult1\itap0{\s29\f0\fs24\lang1033{\*\listtag0}\abinodiroverride\ltrch Open csv files in a spreadsheet editor like Excel or LibreOffice and using Text to columns option split 1st column by tab. Select the outputted columns and sort according to last column in descending order.}{\s29\f0\fs24\lang1033{\*\listtag0}\par}
}{\listtext\pard\fi-427\li720 vi.	}\pard\plain{\ltrpar\ql\fi-427\li720\s29{\*\abilist\abilistid1000\abilistparentid0\abilistlevel1\abistartat1{\abifieldfont NULL}{\abilistdecimal .}{\abilistdelim %L.}{\abiliststyle Lower Roman List}}{\*\pn\pnql\pnstart1\pnlvlbody\pnlcrm{\pntxtb }{\pntxta .}}\fn-427\li720\ls4\ilvl0\sl240\slmult1\itap0{\s29\f0\fs24\lang1033{\*\listtag0}\abinodiroverride\ltrch The last column will give the count of co-occurring hash tags in descending order. On scrolling down we can see relative frequencies which are floating point numbers.}{\s29\f0\fs24\lang1033{\*\listtag0}\par}
}{\listtext\pard\fi-427\li720 vii.	}\pard\plain{\ltrpar\ql\fi-427\li720\s29{\*\abilist\abilistid1000\abilistparentid0\abilistlevel1\abistartat1{\abifieldfont NULL}{\abilistdecimal .}{\abilistdelim %L.}{\abiliststyle Lower Roman List}}{\*\pn\pnql\pnstart1\pnlvlbody\pnlcrm{\pntxtb }{\pntxta .}}\fn-427\li720\ls4\ilvl0\sl240\slmult1\itap0{\s29\f0\fs24\lang1033{\*\listtag0}\abinodiroverride\ltrch Delete all files in /input folder of dfs and run jar file for stripes. It is present as stripes.jar in Jars folder. Type \uc1\u8220\'93}{\s29\f1\fs24\lang1033{\*\listtag0}hadoop jar stripcount-sample.jar sample.WordCount\uc1\u8221\'94 in terminal and follow the same steps as for pairs.}{\s29\f0\fs24\lang1033{\*\listtag0}\par}
}\pard\plain\ltrpar\ql\s29\sl240\slmult1\itap0{\s29\f1\fs24\lang1033{\*\listtag0}\par}
\pard\plain\ltrpar\ql\s29\sl240\slmult1\itap0{\s29\f1\fs24\ul\lang1033{\*\listtag0}\abinodiroverride\ltrch . }{\s29\f0\fs24\ul\lang1033{\*\listtag0}Map Reduce job to perform K-Means algorithm to cluster no. of followers of users into 3 clusters.}{\s29\f1\fs24\ul\lang1033{\*\listtag0}\par}
\pard\plain\ltrpar\ql\s29\sl240\slmult1\itap0{\s29\f0\fs24\ul\lang1033{\*\listtag0}\par}
{\listtext\pard\fi-427\li720 i.	}\pard\plain{\ltrpar\ql\fi-427\li720\s29{\*\abilist\abilistid1061\abilistparentid0\abilistlevel1\abistartat1{\abifieldfont NULL}{\abilistdecimal .}{\abilistdelim %L.}{\abiliststyle Lower Roman List}}{\*\pn\pnql\pnstart1\pnlvlbody\pnlcrm{\pntxtb }{\pntxta .}}\fn-427\li720\ls5\ilvl0\sl240\slmult1\itap0{\s29\f0\fs24\lang1033{\*\listtag0}\abinodiroverride\ltrch Delete all files from the /input folder.}{\s29\f0\fs24\ul\lang1033{\*\listtag0}\par}
}{\listtext\pard\fi-427\li720 ii.	}\pard\plain{\ltrpar\ql\fi-427\li720\s29{\*\abilist\abilistid1061\abilistparentid0\abilistlevel1\abistartat1{\abifieldfont NULL}{\abilistdecimal .}{\abilistdelim %L.}{\abiliststyle Lower Roman List}}{\*\pn\pnql\pnstart1\pnlvlbody\pnlcrm{\pntxtb }{\pntxta .}}\fn-427\li720\ls5\ilvl0\sl240\slmult1\itap0{\s29\f0\fs24\lang1033{\*\listtag0}\abinodiroverride\ltrch Upload the \uc1\u8220\'93}{\s29\f1\fs24\lang1033{\*\listtag0}usernames_graph_short.txt}{\s29\f0\fs24\lang1033{\*\listtag0}\uc1\u8221\'94 file in the /input folder which is the shortened version of }{\s29\f1\fs24\lang1033{\*\listtag0}usernames_graph.txt.}{\s29\f0\fs24\lang1033{\*\listtag0}\par}
}{\listtext\pard\fi-427\li720 iii.	}\pard\plain{\ltrpar\ql\fi-427\li720\s29{\*\abilist\abilistid1061\abilistparentid0\abilistlevel1\abistartat1{\abifieldfont NULL}{\abilistdecimal .}{\abilistdelim %L.}{\abiliststyle Lower Roman List}}{\*\pn\pnql\pnstart1\pnlvlbody\pnlcrm{\pntxtb }{\pntxta .}}\fn-427\li720\ls5\ilvl0\sl240\slmult1\itap0{\s29\f1\fs24\lang1033{\*\listtag0}\abinodiroverride\ltrch Run Kmeans jar file to start Map reduce job as \uc1\u8220\'93  hadoop jar Kmeans-sample.jar sample.KmeansDriver\uc1\u8221\'94}{\s29\f1\fs24\lang1033{\*\listtag0}\par}
}{\listtext\pard\fi-427\li720 iv.	}\pard\plain{\ltrpar\ql\fi-427\li720\s29{\*\abilist\abilistid1061\abilistparentid0\abilistlevel1\abistartat1{\abifieldfont NULL}{\abilistdecimal .}{\abilistdelim %L.}{\abiliststyle Lower Roman List}}{\*\pn\pnql\pnstart1\pnlvlbody\pnlcrm{\pntxtb }{\pntxta .}}\fn-427\li720\ls5\ilvl0\sl240\slmult1\itap0{\s29\f1\fs24\lang1033{\*\listtag0}\abinodiroverride\ltrch The program will create a result.txt file in / folder of dfs.}{\s29\f1\fs24\lang1033{\*\listtag0}\par}
}{\listtext\pard\fi-427\li720 v.	}\pard\plain{\ltrpar\ql\fi-427\li720\s29{\*\abilist\abilistid1061\abilistparentid0\abilistlevel1\abistartat1{\abifieldfont NULL}{\abilistdecimal .}{\abilistdelim %L.}{\abiliststyle Lower Roman List}}{\*\pn\pnql\pnstart1\pnlvlbody\pnlcrm{\pntxtb }{\pntxta .}}\fn-427\li720\ls5\ilvl0\sl240\slmult1\itap0{\s29\f1\fs24\lang1033{\*\listtag0}\abinodiroverride\ltrch After the program runs type hdfs dfs -copyToLocal /result.txt. This file contains the details of step- by step cluster formation.}{\s29\f1\fs24\lang1033{\*\listtag0}\par}
}{\listtext\pard\fi-427\li720 vi.	}\pard\plain{\ltrpar\ql\fi-427\li720\s29{\*\abilist\abilistid1061\abilistparentid0\abilistlevel1\abistartat1{\abifieldfont NULL}{\abilistdecimal .}{\abilistdelim %L.}{\abiliststyle Lower Roman List}}{\*\pn\pnql\pnstart1\pnlvlbody\pnlcrm{\pntxtb }{\pntxta .}}\fn-427\li720\ls5\ilvl0\sl240\slmult1\itap0{\s29\f1\fs24\lang1033{\*\listtag0}\abinodiroverride\ltrch If you want centroids type hdfs dfs -copyToLocal /cluster_details.txt}{\s29\f1\fs24\lang1033{\*\listtag0}\par}
}\pard\plain\ltrpar\ql\s29\sl240\slmult1\itap0{\s29\f1\fs24\lang1033{\*\listtag0}\par}
\pard\plain\ltrpar\ql\s29\sl240\slmult1\itap0{\s29\f1\fs24\ul\lang1033{\*\listtag0}\abinodiroverride\ltrch . Shortest Path}{\s29\f1\fs24\ul\lang1033{\*\listtag0}\par}
\pard\plain\ltrpar\ql\s29\sl240\slmult1\itap0{\s29\f1\fs24\ul\lang1033{\*\listtag0}\par}
{\listtext\pard\fi-427\li720 i.	}\pard\plain{\ltrpar\ql\fi-427\li720\s29{\*\abilist\abilistid1052\abilistparentid0\abilistlevel1\abistartat1{\abifieldfont NULL}{\abilistdecimal .}{\abilistdelim %L.}{\abiliststyle Lower Roman List}}{\*\pn\pnql\pnstart1\pnlvlbody\pnlcrm{\pntxtb }{\pntxta .}}\fn-427\li720\ls6\ilvl0\sl240\slmult1\itap0{\s29\f1\fs24\lang1033{\*\listtag0}\abinodiroverride\ltrch Create a folder in dfs by typing \uc1\u8220\'93hdfs dfs -mkdir /SPath\uc1\u8221\'94.}{\s29\f1\fs24\ul\lang1033{\*\listtag0}\par}
}{\listtext\pard\fi-427\li720 ii.	}\pard\plain{\ltrpar\ql\fi-427\li720\s29{\*\abilist\abilistid1052\abilistparentid0\abilistlevel1\abistartat1{\abifieldfont NULL}{\abilistdecimal .}{\abilistdelim %L.}{\abiliststyle Lower Roman List}}{\*\pn\pnql\pnstart1\pnlvlbody\pnlcrm{\pntxtb }{\pntxta .}}\fn-427\li720\ls6\ilvl0\sl240\slmult1\itap0{\s29\f1\fs24\lang1033{\*\listtag0}\abinodiroverride\ltrch Rename graph data as graph.txt and upload to /SPath folder in dfs. }{\s29\f1\fs24\lang1033{\*\listtag0}\par}
}{\listtext\pard\fi-427\li720 iii.	}\pard\plain{\ltrpar\ql\fi-427\li720\s29{\*\abilist\abilistid1052\abilistparentid0\abilistlevel1\abistartat1{\abifieldfont NULL}{\abilistdecimal .}{\abilistdelim %L.}{\abiliststyle Lower Roman List}}{\*\pn\pnql\pnstart1\pnlvlbody\pnlcrm{\pntxtb }{\pntxta .}}\fn-427\li720\ls6\ilvl0\sl240\slmult1\itap0{\s29\f0\fs24\lang1033{\*\listtag0}\abinodiroverride\ltrch Run jar }{\s29\f0\fs24\lang1033{\*\listtag0}shortestpath}{\s29\f0\fs24\lang1033{\*\listtag0}-sample.jar by typing \uc1\u8220\'93hadoop jar }{\s29\f0\fs24\lang1033{\*\listtag0}shortestpath}{\s29\f0\fs24\lang1033{\*\listtag0}-sample.jar sample.ShortestPath\uc1\u8221\'94}{\s29\f1\fs24\lang1033{\*\listtag0}\par}
}{\listtext\pard\fi-427\li720 iv.	}\pard\plain{\ltrpar\ql\fi-427\li720\s29{\*\abilist\abilistid1052\abilistparentid0\abilistlevel1\abistartat1{\abifieldfont NULL}{\abilistdecimal .}{\abilistdelim %L.}{\abiliststyle Lower Roman List}}{\*\pn\pnql\pnstart1\pnlvlbody\pnlcrm{\pntxtb }{\pntxta .}}\fn-427\li720\ls6\ilvl0\sl240\slmult1\itap0{\s29\f0\fs24\lang1033{\*\listtag0}\abinodiroverride\ltrch After running a file ,many folders of the format part-r-00000* is created in /. copy to local the file with most recent timestamp to local. This file contains the required result. Type \uc1\u8220\'93hdfs dfs -ls /\uc1\u8221\'94. and then , hdfs dfs -copyToLocal /part-r-00000* .}{\s29\f0\fs24\lang1033{\*\listtag0}\par}}}